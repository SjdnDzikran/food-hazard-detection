\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{hidelinks}

\begin{document}

\title{Food Hazard Detection with a Multi-Task BERT for SemEval 2025 Task 9}

\author{\IEEEauthorblockN{Gafna Al Faatiha Prabowo (23/513334/PA/21930), Dzikran Azka Sajidan (23/516665/PA/22110), Muhammad Khairul Hasbi (23/519845/PA/22310), Rifky Setiawan (23/519942/PA/22326)}
\IEEEauthorblockA{\textit{Department of Computer Science, Universitas Gadjah Mada}\\
Yogyakarta, Indonesia\\
Email: \{gafnaalfaatihaprabowo, dzikranazkasajidan, muhammadkhairulhasbi2004, rifkysetiawan\}@mail.ugm.ac.id}
}

\maketitle

\begin{abstract}
Kami berpartisipasi dalam SemEval 2025 Task 9 (Food Hazard Detection), Sub-Task 1, yang menuntut prediksi label hazard-category dan product-category dari judul recall makanan yang sangat pendek. Sistem kami memakai arsitektur multi-task berbasis \texttt{bert-base-uncased} dengan dua classification heads (hazard dan product) dan class weights untuk mengatasi imbalance. Macro F1 adalah metrik utama; secara internal kami merata-ratakan macro F1 hazard dan product, sementara skor resmi hanya menghitung product F1 bila hazard benar. Pada dataset latih berisi 5{,}082 judul, model terbaik kami mencapai hazard macro F1 0{,}718 dan product macro F1 0{,}640 (combined 0{,}679) di validasi, serta hazard 0{,}604 dan product 0{,}654 (combined 0{,}629) pada test blind. Kami menguraikan preprocessing, setup pelatihan (tokenisasi panjang 256, AdamW + linear warmup, early stopping), serta rencana ablation menuju submission akhir di Codalab.
\end{abstract}

\begin{IEEEkeywords}
SemEval 2025, food safety, multi-task classification, transformers, class imbalance.
\end{IEEEkeywords}

\section{Pendahuluan}
Keamanan pangan merupakan isu kesehatan publik yang krusial. Kategorisasi cepat terhadap bahaya (hazard) dan produk dari laporan recall sangat penting untuk respons tepat waktu, namun proses manual memerlukan waktu dan tenaga signifikan. SemEval 2025 Task 9 menangani ini dengan menyediakan framework untuk kategorisasi otomatis dari judul recall yang sangat singkat ($\sim$88 karakter). Sub-Task 1 memerlukan prediksi simultan hazard-category (10 kelas) dan product-category (22 kelas), dengan tantangan: teks sangat pendek, distribusi label sangat tidak seimbang, dan evaluasi macro F1 yang menekankan performa pada semua kelas.

Kami mengembangkan sistem multi-task berbasis \texttt{bert-base-uncased} dengan dua classification heads dan class weights untuk menangani imbalance. Model mencapai combined macro F1 0{,}679 pada validasi dan 0{,}629 pada test set. Kontribusi kami: (1) arsitektur multi-task BERT dengan penanganan class imbalance, (2) pipeline pelatihan dengan early stopping berbasis combined macro F1, dan (3) analisis gap validasi-test yang mengidentifikasi tantangan pada hazard minoritas.

\section{Metodologi}
\subsection{Tinjauan Pustaka}
Transformer-based encoders seperti BERT \cite{devlin2019bert} telah menjadi arsitektur standar untuk klasifikasi teks, menunjukkan performa unggul pada berbagai tugas NLP termasuk klasifikasi short-text. Pre-trained language models ini memanfaatkan self-attention mechanism untuk menangkap dependensi kontekstual dalam teks. Untuk tugas multi-label atau multi-task, pendekatan umum adalah menambahkan classification heads terpisah di atas shared encoder.

Class imbalance merupakan tantangan umum dalam klasifikasi, terutama dengan distribusi long-tail. Focal loss \cite{lin2017focal} dirancang untuk mengurangi bobot sampel yang mudah diklasifikasi dan fokus pada kasus sulit. Alternatif lain adalah class weighting yang memberikan bobot lebih tinggi pada kelas minoritas dalam loss function. Dalam konteks keamanan pangan, deteksi hazard otomatis masih terbatas, dengan sebagian besar studi fokus pada identifikasi keberadaan hazard, bukan kategorisasi detil dari teks pendek.

\subsection{Tugas dan Data}
Input berupa judul recall makanan berbahasa Inggris dengan metadata (year, month, day, country). Output adalah dua prediksi single-label: hazard-category (10 kelas) dan product-category (22 kelas). Skor resmi macro F1 menghitung rata-rata hazard F1 dan product F1, namun product F1 hanya diambil pada sampel dengan prediksi hazard yang benar.

Kami memakai train set (5{,}082 sampel) dan validation set (565 sampel); test terdiri dari 997 sampel. Judul sangat singkat (rata-rata $\sim$88 karakter) dan distribusi label sangat imbalanced, terutama pada hazard minoritas (mis. kontaminan kimia tertentu). Label dienkode dengan \texttt{LabelEncoder} untuk hazard dan product; class weights dihitung dari distribusi train.

\subsection{Gambaran Model}
Kami menggunakan \texttt{bert-base-uncased} dengan arsitektur multi-task dua head: hazard head dan product head (linear 768$\rightarrow$kelas) di atas pooled output BERT. Dropout 0{,}2 diterapkan sebelum kedua head. Tidak ada engineered features atau fusion jalur kedua pada versi ini; fokus pada fine-tuning teks dengan penanganan imbalance.

\subsection{Implementasi}
\textbf{Preprocessing}: Judul ditokenisasi dengan \texttt{BertTokenizer} (\texttt{bert-base-uncased}), max length 256, dengan padding dan truncation. Token type ids dipertahankan untuk kompatibilitas BERT. Pada eksperimen ini, tidak ada fitur tambahan dari metadata yang digunakan.

\textbf{Training}: Model di-fine-tune hingga 8 epoch dengan optimizer AdamW (learning rate $2\times10^{-5}$, weight decay 0{,}01), batch size 16. Linear warmup scheduler diterapkan pada 10\% langkah awal. Loss function adalah penjumlahan dua \texttt{CrossEntropyLoss} dengan class weights untuk hazard dan product heads. Gradient clipping pada norm 1{,}0 digunakan untuk stabilitas. Early stopping dengan patience 2 berdasarkan combined macro F1 validasi (rata-rata arithmetic hazard dan product F1).

\subsection{Evaluasi}
Dataset dibagi menjadi train (5{,}082 sampel), validation (565 sampel), dan test (997 sampel). Test set tidak memiliki label publik; evaluasi dilakukan secara blind melalui platform Codalab. Metrik evaluasi utama adalah combined macro F1, yang merupakan rata-rata dari hazard macro F1 dan product macro F1. Skor resmi menggunakan protokol khusus di mana product F1 hanya dihitung pada sampel dengan prediksi hazard yang benar.

\section{Hasil dan Analisis}
\subsection{Performa Model}
Table~\ref{tab:results} menunjukkan performa model terbaik pada validation dan test sets. Model mencapai combined macro F1 sebesar 0{,}679 pada validation set, dengan hazard F1 (0{,}718) lebih tinggi dari product F1 (0{,}640). Pada test set, combined macro F1 mencapai 0{,}629, dengan product F1 (0{,}654) sedikit lebih tinggi dari hazard F1 (0{,}604). Penurunan hazard F1 dari validasi ke test sebesar 0{,}114 poin mengindikasikan overfitting pada kategori hazard tertentu.

Figure~\ref{fig:f1curves} menunjukkan kurva learning selama pelatihan. Model konvergen setelah epoch ke-4, dengan hazard F1 konsisten lebih tinggi dari product F1 pada validation set. Early stopping dipicu pada epoch ke-6 berdasarkan combined macro F1.

\begin{table}[htbp]
\caption{Macro F1 Scores (best run)}
\label{tab:results}
\centering
\begin{tabular}{lccc}
\hline
Split & Hazard F1 & Product F1 & Combined \\
\hline
Validation (best epoch) & 0.7183 & 0.6397 & 0.6790 \\
Test (blind) & 0.6043 & 0.6544 & 0.6293 \\
\hline
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.45\textwidth]{figures/f1_curves.png}
\caption{Validation macro F1 per epoch for hazard, product, and combined scores.}
\label{fig:f1curves}
\end{figure}

\subsection{Analisis}
Analisis performa model mengungkapkan beberapa temuan penting:

\begin{enumerate}
    \item \textbf{Validasi vs Test Gap}
    
    Perbedaan signifikan antara hazard F1 pada validation (0{,}718) dan test (0{,}604) mengindikasikan overfitting pada distribusi hazard dalam training set. Sebaliknya, product head menunjukkan generalisasi lebih baik dengan F1 test (0{,}654) bahkan lebih tinggi dari validation (0{,}640), menunjukkan robustness terhadap domain shift.
    
    \item \textbf{Error Analysis}
    
    Analisis kesalahan menunjukkan error mengelompok pada kategori hazard minoritas. Confusion matrix mengungkapkan bahwa kategori dominan seperti \textit{biological} dan \textit{chemical} sering menyerap prediksi dari kelas langka, mencerminkan bias model terhadap kelas mayoritas meskipun telah menggunakan class weights.
    
    \item \textbf{Implikasi}
    
    Product head yang lebih stabil mengindikasikan bahwa signal untuk kategorisasi produk lebih konsisten across splits. Hazard classification lebih menantang karena dependensi pada kata kunci spesifik yang mungkin berbeda distribusinya antar splits. Peningkatan performa memerlukan strategi penanganan imbalance yang lebih agresif, khususnya untuk hazard minoritas.
\end{enumerate}

\section{Kesimpulan dan Pekerjaan Lanjutan}
Kami memaparkan sistem Transformer multi-task berbasis BERT untuk SemEval 2025 Task 9 Sub-Task 1 yang berhasil mengklasifikasikan hazard dan product categories dari judul recall makanan yang sangat pendek. Model \texttt{bert-base-uncased} dengan dua classification heads dan class weights mencapai combined macro F1 sebesar 0{,}679 pada validation set dan 0{,}629 pada test blind set. Hasil ini menunjukkan bahwa pendekatan multi-task learning efektif untuk tugas klasifikasi ganda pada teks singkat dengan distribusi label yang tidak seimbang.

Pekerjaan lanjutan mencakup beberapa arah:
\begin{itemize}
    \item \textbf{Penanganan imbalance yang lebih baik}: menjalankan ablation untuk membandingkan class weights vs focal loss, serta eksplorasi teknik oversampling untuk meningkatkan recall pada hazard minoritas.
    \item \textbf{Arsitektur alternatif}: mencoba encoder yang lebih besar seperti \texttt{roberta-base} atau \texttt{roberta-large} jika sumber daya komputasi mencukupi.
    \item \textbf{Feature engineering}: menambahkan fitur tambahan dari metadata (country, temporal features) dalam kerangka dual-path untuk memperkaya representasi.
    \item \textbf{Domain-adaptive pretraining}: memanfaatkan data tak berlabel dari domain keamanan pangan untuk meningkatkan kemampuan generalisasi model.
\end{itemize}

Kode sumber lengkap tersedia di \url{https://github.com/SjdnDzikran/food-hazard-detection}.

\begin{thebibliography}{00}
\bibitem{devlin2019bert} J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ``BERT: Pre-training of deep bidirectional transformers for language understanding,'' in \textit{Proc. NAACL-HLT}, 2019.
\bibitem{lin2017focal} T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Doll{\'a}r, ``Focal loss for dense object detection,'' in \textit{Proc. ICCV}, 2017.
\end{thebibliography}

\end{document}
