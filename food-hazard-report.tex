\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{hidelinks}

\begin{document}

\title{Food Hazard Detection with a Multi-Task BERT for SemEval 2025 Task 9}

\author{\IEEEauthorblockN{Gafna Al Faatiha Prabowo (23/513334/PA/21930)\\Dzikran Azka Sajidan (23/516665/PA/22110)\\Muhammad Khairul Hasbi (23/519845/PA/22310)\\Rifky Setiawan (23/519942/PA/22326)}
\IEEEauthorblockA{\textit{Department of Computer Science, Universitas Gadjah Mada}\\
Yogyakarta, Indonesia\\
Email: \{gafnaalfaatihaprabowo, dzikranazkasajidan, muhammadkhairulhasbi2004, rifkysetiawan\}@mail.ugm.ac.id}
}

\maketitle

\begin{abstract}
Kami berpartisipasi dalam SemEval 2025 Task 9 (Food Hazard Detection), Sub-Task 1, yang menuntut prediksi label hazard-category dan product-category dari judul recall makanan yang sangat pendek. Sistem kami memakai arsitektur multi-task berbasis \texttt{bert-base-uncased} dengan dua classification heads (hazard dan product) dan class weights untuk mengatasi imbalance. Macro F1 adalah metrik utama; secara internal kami merata-ratakan macro F1 hazard dan product, sementara skor resmi hanya menghitung product F1 bila hazard benar. Pada dataset latih berisi 5{,}082 judul, model terbaik kami mencapai hazard macro F1 0{,}718 dan product macro F1 0{,}640 (combined 0{,}679) di validasi, serta hazard 0{,}604 dan product 0{,}654 (combined 0{,}629) pada test blind. Kami menguraikan preprocessing, setup pelatihan (tokenisasi panjang 256, AdamW + linear warmup, early stopping), serta rencana ablation menuju submission akhir di Codalab.
\end{abstract}

\begin{IEEEkeywords}
SemEval 2025, food safety, multi-task classification, transformers, class imbalance.
\end{IEEEkeywords}

\section{Pendahuluan}
Keamanan pangan merupakan isu kesehatan publik yang krusial. Kategorisasi cepat terhadap bahaya (hazard) dan produk dari laporan recall sangat penting untuk respons tepat waktu, namun proses manual memerlukan waktu dan tenaga signifikan. SemEval 2025 Task 9 menangani ini dengan menyediakan framework untuk kategorisasi otomatis dari judul recall yang sangat singkat ($\sim$88 karakter). Sub-Task 1 memerlukan prediksi simultan hazard-category (10 kelas) dan product-category (22 kelas), dengan tantangan: teks sangat pendek, distribusi label sangat tidak seimbang, dan evaluasi macro F1 yang menekankan performa pada semua kelas.

Kami mengembangkan sistem multi-task berbasis \texttt{bert-base-uncased} dengan dua classification heads dan class weights untuk menangani imbalance. Model mencapai combined macro F1 0{,}679 pada validasi dan 0{,}629 pada test set. Kontribusi kami: (1) arsitektur multi-task BERT dengan penanganan class imbalance, (2) pipeline pelatihan dengan early stopping berbasis combined macro F1, dan (3) analisis gap validasi-test yang mengidentifikasi tantangan pada hazard minoritas.

\section{Metodologi}
\subsection{Tinjauan Pustaka}
Transformer-based encoders seperti BERT \cite{devlin2019bert} telah menjadi arsitektur standar untuk klasifikasi teks, menunjukkan performa unggul pada berbagai tugas NLP termasuk klasifikasi short-text. Pre-trained language models ini memanfaatkan self-attention mechanism untuk menangkap dependensi kontekstual dalam teks. Untuk tugas multi-label atau multi-task, pendekatan umum adalah menambahkan classification heads terpisah di atas shared encoder.

Class imbalance merupakan tantangan umum dalam klasifikasi, terutama dengan distribusi long-tail. Focal loss \cite{lin2017focal} dirancang untuk mengurangi bobot sampel yang mudah diklasifikasi dan fokus pada kasus sulit. Alternatif lain adalah class weighting yang memberikan bobot lebih tinggi pada kelas minoritas dalam loss function. Dalam konteks keamanan pangan, deteksi hazard otomatis masih terbatas, dengan sebagian besar studi fokus pada identifikasi keberadaan hazard, bukan kategorisasi detil dari teks pendek.

\subsection{Tugas dan Data}
Input berupa judul recall makanan berbahasa Inggris dengan metadata (year, month, day, country). Output adalah dua prediksi single-label: hazard-category (10 kelas) dan product-category (22 kelas). Skor resmi macro F1 menghitung rata-rata hazard F1 dan product F1, namun product F1 hanya diambil pada sampel dengan prediksi hazard yang benar.

Kami memakai train set (5{,}082 sampel) dan validation set (565 sampel); test terdiri dari 997 sampel. Judul sangat singkat (rata-rata $\sim$88 karakter) dan distribusi label sangat imbalanced, terutama pada hazard minoritas (mis. kontaminan kimia tertentu). Label dienkode dengan \texttt{LabelEncoder} untuk hazard dan product; class weights dihitung dari distribusi train.

\subsection{Gambaran Model}
Kami menggunakan \texttt{bert-base-uncased} dengan arsitektur multi-task dua head: hazard head dan product head (linear 768$\rightarrow$kelas) di atas pooled output BERT. Dropout 0{,}2 diterapkan sebelum kedua head. Tidak ada engineered features atau fusion jalur kedua pada versi ini; fokus pada fine-tuning teks dengan penanganan imbalance.

\subsection{Implementasi}
\textbf{Preprocessing}: Judul ditokenisasi dengan \texttt{BertTokenizer} (\texttt{bert-base-uncased}), max length 256, dengan padding dan truncation. Token type ids dipertahankan untuk kompatibilitas BERT. Pada eksperimen ini, tidak ada fitur tambahan dari metadata yang digunakan.

\textbf{Training}: Model di-fine-tune hingga 8 epoch dengan optimizer AdamW (learning rate $2\times10^{-5}$, weight decay 0{,}01), batch size 16. Linear warmup scheduler diterapkan pada 10\% langkah awal. Loss function adalah penjumlahan dua \texttt{CrossEntropyLoss} dengan class weights untuk hazard dan product heads. Gradient clipping pada norm 1{,}0 digunakan untuk stabilitas. Early stopping dengan patience 2 berdasarkan combined macro F1 validasi (rata-rata arithmetic hazard dan product F1).

\subsection{Evaluasi}
Dataset dibagi menjadi train (5{,}082 sampel), validation (565 sampel), dan test (997 sampel). Test set tidak memiliki label publik; evaluasi dilakukan secara blind melalui platform Codalab. Metrik evaluasi utama adalah combined macro F1, yang merupakan rata-rata dari hazard macro F1 dan product macro F1. Skor resmi menggunakan protokol khusus di mana product F1 hanya dihitung pada sampel dengan prediksi hazard yang benar.

\section{Hasil dan Analisis}
\subsection{Performa Model}

\begin{table}[htbp]
\caption{Macro F1 Scores (best run)}
\label{tab:results}
\centering
\begin{tabular}{lccc}
\hline
Split & Hazard F1 & Product F1 & Combined \\
\hline
Validation (best epoch) & 0.7183 & 0.6397 & 0.6790 \\
Test (blind) & 0.6043 & 0.6544 & 0.6293 \\
\hline
\end{tabular}
\end{table}

\noindent\hspace*{0.6em}
Table~\ref{tab:results} menunjukkan performa model terbaik pada validation dan test sets. Model mencapai combined macro F1 sebesar 0{,}679 pada validation set, dengan hazard F1 (0{,}718) lebih tinggi dari product F1 (0{,}640). Pada test set, combined macro F1 mencapai 0{,}629, dengan product F1 (0{,}654) sedikit lebih tinggi dari hazard F1 (0{,}604). Penurunan hazard F1 dari validasi ke test sebesar 0{,}114 poin mengindikasikan overfitting pada kategori hazard tertentu.

Hasil visualisasi tersebut menunjukkan beberapa pola penting: (1) performa hazard F1 lebih rendah dibanding product F1 pada test set, menegaskan bahwa hazard classification lebih sulit akibat distribusi label yang tidak seimbang; (2) confusion matrix menegaskan bahwa model cenderung mengkonversi banyak kelas minoritas ke kelas mayoritas; dan (3) kurva training loss serta tabel per-epoch memperlihatkan bahwa model mengalami konvergensi stabil tanpa indikasi underfitting.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.45\textwidth]{figures/training_loss.png}
\caption{Kurva training loss per epoch. Penurunan loss yang stabil mengindikasikan proses pembelajaran yang konvergen.}
\label{fig:trainloss}
\end{figure}

\noindent\hspace*{0.6em}
Figure~\ref{fig:trainloss} menunjukkan penurunan yang konsisten dari epoch 1 hingga epoch 8, dengan pola kurva eksponensial yang umum terjadi pada model Transformer. Penurunan loss yang halus tanpa fluktuasi besar mengindikasikan bahwa proses optimisasi berjalan stabil. Namun, karena gap performa antara validation dan test cukup signifikan pada hazard classification, hal ini menunjukkan bahwa meskipun model belajar dengan baik, ia belum mampu mengeneralisasi secara optimal pada kategori minoritas.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.45\textwidth]{figures/f1_curves.png}
\caption{Validation macro F1 per epoch for hazard, product, and combined scores.}
\label{fig:f1curves}
\end{figure}

\noindent\hspace*{0.6em}
Figure~\ref{fig:f1curves} menunjukkan kurva learning selama pelatihan. Model konvergen setelah epoch ke-4, dengan hazard F1 konsisten lebih tinggi dari product F1 pada validation set. Early stopping dipicu pada epoch ke-6 berdasarkan combined macro F1.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.45\textwidth]{figures/barchart_finaltest.png}
\caption{Macro F1 pada data test untuk hazard, product, dan combined. Grafik ini menunjukkan bahwa model mencapai performa terbaik pada tugas product classification.}
\label{fig:testbarchart}
\end{figure}

\noindent\hspace*{0.6em}
Figure~\ref{fig:testbarchart} menyajikan skor Macro F1 pada data test untuk tiga task yang dievaluasi: hazard classification, product classification, dan combined metric. Terlihat bahwa skor tertinggi dicapai pada product classification ($\approx 0{,}65$), diikuti oleh combined ($\approx 0{,}63$), sementara hazard classification menunjukkan performa terendah ($\approx 0{,}60$).

Perbedaan ini menegaskan bahwa hazard detection merupakan task yang lebih menantang akibat distribusi label yang tidak seimbang serta deskripsi tekstual yang lebih beragam dan ambigu. Sebaliknya, task product cenderung lebih stabil karena variasi label yang lebih terstruktur.

\begin{table}[htbp]
\centering
\caption{Training dan validation metrics per epoch.}
\label{tab:trainmetrics}
\begin{tabular}{rrrrrr}
\hline
 Epoch &  Train Loss &  Val Hazard F1 &  Val Product F1 &  Combined F1 \\
\hline
     1 &      5.1489 &         0.3708 &          0.1744 &       0.2726 \\
     2 &      3.7313 &         0.6057 &          0.4967 &       0.5512 \\
     3 &      2.7637 &         0.6294 &          0.5529 &       0.5912 \\
     4 &      2.1449 &         0.6813 &          0.6069 &       0.6441 \\
     5 &      1.7425 &         0.6819 &          0.6232 &       0.6526 \\
     6 &      1.4737 &         0.7053 &          0.6291 &       0.6672 \\
     7 &      1.2618 &         0.7052 &          0.6313 &       0.6683 \\
     8 &      1.1647 &         0.7183 &          0.6397 &       0.6790 \\
\hline
\end{tabular}
\end{table}

\noindent\hspace*{0.6em}
Table~\ref{tab:trainmetrics} merangkum metrik utama pada setiap epoch: training loss, hazard F1, product F1, dan combined metric.
Dari tabel terlihat bahwa:

\begin{itemize}
    \item Training loss menurun tajam dari 5.15 ke 1.16, menandakan proses optimisasi efektif.
    \item Hazard F1 meningkat dari 0.37 ke 0.71, menunjukkan pembelajaran kelas hazard berlangsung substansial.
    \item Product F1 meningkat lebih stabil, dari 0.17 ke 0.64.
    \item Combined metric mencapai nilai tertinggi 0.679 pada epoch 8.
\end{itemize}

\noindent\hspace*{0.6em}
Tabel ini memperlihatkan pola konsisten seperti pada grafik, sekaligus menjadi bukti kuantitatif bahwa performa model terus meningkat selama pelatihan hingga mencapai konvergensi.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.45\textwidth]{figures/cm.png}
\caption{Confusion matrix untuk kategori hazard. Dominasi prediksi pada kelas mayoritas memperlihatkan masalah imbalance yang signifikan.}
\label{fig:hazcm}
\end{figure}

\noindent\hspace*{0.6em}
Figure~\ref{fig:hazcm} menggambarkan distribusi prediksi model terhadap label sebenarnya untuk kategori hazard. Matriks ini memperlihatkan bahwa sebagian besar prediksi terkonsentrasi pada beberapa kelas mayoritas, seperti allergens dan biological, sementara kelas minoritas seperti migration, organoleptic aspects, dan food additives hampir selalu salah diprediksi.

Fenomena ini menunjukkan bahwa model sangat dipengaruhi oleh class imbalance, sehingga tidak mampu membedakan fitur khas dari kategori yang jarang muncul. Hal ini menjadi indikasi kuat bahwa strategi seperti re-weighting, oversampling, atau focal loss diperlukan untuk meningkatkan sensitivitas terhadap kelas minoritas.

\subsection{Analisis}
Analisis performa model mengungkapkan beberapa temuan penting:

\begin{enumerate}
    \item \textbf{Validasi vs Test Gap}
    
    Perbedaan signifikan antara hazard F1 pada validation (0{,}718) dan test (0{,}604) mengindikasikan overfitting pada distribusi hazard dalam training set. Sebaliknya, product head menunjukkan generalisasi lebih baik dengan F1 test (0{,}654) bahkan lebih tinggi dari validation (0{,}640), menunjukkan robustness terhadap domain shift.
    
    \item \textbf{Error Analysis}
    
    Analisis kesalahan menunjukkan error mengelompok pada kategori hazard minoritas. Confusion matrix mengungkapkan bahwa kategori dominan seperti \textit{biological} dan \textit{chemical} sering menyerap prediksi dari kelas langka, mencerminkan bias model terhadap kelas mayoritas meskipun telah menggunakan class weights.
    
    \item \textbf{Implikasi}
    
    Product head yang lebih stabil mengindikasikan bahwa signal untuk kategorisasi produk lebih konsisten across splits. Hazard classification lebih menantang karena dependensi pada kata kunci spesifik yang mungkin berbeda distribusinya antar splits. Peningkatan performa memerlukan strategi penanganan imbalance yang lebih agresif, khususnya untuk hazard minoritas.
\end{enumerate}

\section{Kesimpulan dan Pekerjaan Lanjutan}
Kami memaparkan sistem Transformer multi-task berbasis BERT untuk SemEval 2025 Task 9 Sub-Task 1 yang berhasil mengklasifikasikan hazard dan product categories dari judul recall makanan yang sangat pendek. Model \texttt{bert-base-uncased} dengan dua classification heads dan class weights mencapai combined macro F1 sebesar 0{,}679 pada validation set dan 0{,}629 pada test blind set. Hasil ini menunjukkan bahwa pendekatan multi-task learning efektif untuk tugas klasifikasi ganda pada teks singkat dengan distribusi label yang tidak seimbang.

Pekerjaan lanjutan mencakup beberapa arah:
\begin{itemize}
    \item \textbf{Penanganan imbalance yang lebih baik}: menjalankan ablation untuk membandingkan class weights vs focal loss, serta eksplorasi teknik oversampling untuk meningkatkan recall pada hazard minoritas.
    \item \textbf{Arsitektur alternatif}: mencoba encoder yang lebih besar seperti \texttt{roberta-base} atau \texttt{roberta-large} jika sumber daya komputasi mencukupi.
    \item \textbf{Feature engineering}: menambahkan fitur tambahan dari metadata (country, temporal features) dalam kerangka dual-path untuk memperkaya representasi.
    \item \textbf{Domain-adaptive pretraining}: memanfaatkan data tak berlabel dari domain keamanan pangan untuk meningkatkan kemampuan generalisasi model.
\end{itemize}

Kode sumber lengkap tersedia di \url{https://github.com/SjdnDzikran/food-hazard-detection}.

\begin{thebibliography}{00}
\bibitem{devlin2019bert} J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ``BERT: Pre-training of deep bidirectional transformers for language understanding,'' in \textit{Proc. NAACL-HLT}, 2019.
\bibitem{lin2017focal} T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Doll{\'a}r, ``Focal loss for dense object detection,'' in \textit{Proc. ICCV}, 2017.
\end{thebibliography}

\end{document}
